{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP_Sarcasm_Detect",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/npasuparthi/nagendra-AI_ML/blob/master/NLP_Sarcasm_Detect_Nagendra_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5fCEDCU_qrC0"
      },
      "source": [
        "<p><img alt=\"Colaboratory logo\" height=\"45px\" src=\"/img/colab_favicon.ico\" align=\"left\" hspace=\"10px\" vspace=\"0px\"></p>\n",
        "\n",
        "<h1>What is Colaboratory?</h1>\n",
        "\n",
        "Colaboratory, or \"Colab\" for short, allows you to write and execute Python in your browser, with \n",
        "- Zero configuration required\n",
        "- Free access to GPUs\n",
        "- Easy sharing\n",
        "\n",
        "Whether you're a **student**, a **data scientist** or an **AI researcher**, Colab can make your work easier. Watch [Introduction to Colab](https://www.youtube.com/watch?v=inN8seMm7UI) to learn more, or just get started below!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bX4w0zuxE7kI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "080fe299-74e7-4057-b0fc-5a43c57bdc20"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t3CXrmc3HIHO"
      },
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HbMnZTx7HcaC"
      },
      "source": [
        "data = pd.read_json('/content/drive//MyDrive/SarcasmDetect/Sarcasm_Headlines_Dataset.json', lines= True)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "id": "Bymqa01qGjmc",
        "outputId": "648efa84-ba76-4334-9408-68957500b9eb"
      },
      "source": [
        "data.head()"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>is_sarcastic</th>\n",
              "      <th>headline</th>\n",
              "      <th>article_link</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>thirtysomething scientists unveil doomsday clo...</td>\n",
              "      <td>https://www.theonion.com/thirtysomething-scien...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>dem rep. totally nails why congress is falling...</td>\n",
              "      <td>https://www.huffingtonpost.com/entry/donna-edw...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>eat your veggies: 9 deliciously different recipes</td>\n",
              "      <td>https://www.huffingtonpost.com/entry/eat-your-...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>inclement weather prevents liar from getting t...</td>\n",
              "      <td>https://local.theonion.com/inclement-weather-p...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>mother comes pretty close to using word 'strea...</td>\n",
              "      <td>https://www.theonion.com/mother-comes-pretty-c...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   is_sarcastic  ...                                       article_link\n",
              "0             1  ...  https://www.theonion.com/thirtysomething-scien...\n",
              "1             0  ...  https://www.huffingtonpost.com/entry/donna-edw...\n",
              "2             0  ...  https://www.huffingtonpost.com/entry/eat-your-...\n",
              "3             1  ...  https://local.theonion.com/inclement-weather-p...\n",
              "4             1  ...  https://www.theonion.com/mother-comes-pretty-c...\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NoKKr1MlXvbS"
      },
      "source": [
        "# Import stopwords with scikit-learn\n",
        "from sklearn.feature_extraction import text\n",
        "stop = text.ENGLISH_STOP_WORDS"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5IsjKvjKXxzV"
      },
      "source": [
        "#remove stop words\n",
        "data['headline'] = data['headline'].apply(lambda words: ' '.join(word.lower() for word in words.split() if word not in stop))\n",
        "\n"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UwjnLl1ETjml"
      },
      "source": [
        "samples = data['headline'].to_numpy()\n",
        "labels = data['is_sarcastic'].to_numpy()"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "qM_jYFhxXRs4",
        "outputId": "979fe7cc-9748-46a7-bbeb-18f984ef4980"
      },
      "source": [
        "samples[43]"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"new google project delivers critical info refugees' smartphones\""
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nVx_BFBSUqFR"
      },
      "source": [
        "# Shuffle the data\n",
        "seed = 1337\n",
        "rng = np.random.RandomState(seed)\n",
        "rng.shuffle(samples)\n",
        "rng = np.random.RandomState(seed)\n",
        "rng.shuffle(labels)\n",
        "\n",
        "# Extract a training & validation split\n",
        "validation_split = 0.2\n",
        "num_validation_samples = int(validation_split * len(samples))\n",
        "train_samples = samples[:-num_validation_samples]\n",
        "val_samples = samples[-num_validation_samples:]\n",
        "train_labels = labels[:-num_validation_samples]\n",
        "val_labels = labels[-num_validation_samples:]"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cFOTQzp1VlxA"
      },
      "source": [
        "#Create a vocabulary index\n",
        "\n",
        "from tensorflow.keras.layers import TextVectorization\n",
        "\n",
        "vectorizer = TextVectorization(max_tokens=20000, output_sequence_length=200)\n",
        "text_ds = tf.data.Dataset.from_tensor_slices(train_samples).batch(128)\n",
        "vectorizer.adapt(text_ds)"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2UxR9j1dV9Vt",
        "outputId": "cd3ce0a3-8376-4119-93f5-6b0e65b4167f"
      },
      "source": [
        "# top 50 words in the vocabulary are \n",
        "vectorizer.get_vocabulary()[:50]\n"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['',\n",
              " '[UNK]',\n",
              " 'new',\n",
              " 'trump',\n",
              " 'man',\n",
              " 'just',\n",
              " 'report',\n",
              " 'woman',\n",
              " 'area',\n",
              " 'day',\n",
              " 'says',\n",
              " 'donald',\n",
              " 'time',\n",
              " 'us',\n",
              " 'like',\n",
              " 'trumps',\n",
              " 'people',\n",
              " 'house',\n",
              " 'obama',\n",
              " 'white',\n",
              " 'life',\n",
              " 'make',\n",
              " 'women',\n",
              " 'world',\n",
              " 'clinton',\n",
              " 'years',\n",
              " 'americans',\n",
              " 'way',\n",
              " 'family',\n",
              " 'study',\n",
              " 'its',\n",
              " 'gop',\n",
              " 'black',\n",
              " '5',\n",
              " 'nation',\n",
              " 'police',\n",
              " 'really',\n",
              " 'know',\n",
              " 'good',\n",
              " 'cant',\n",
              " 'death',\n",
              " 'finds',\n",
              " 'watch',\n",
              " 'the',\n",
              " 'school',\n",
              " 'big',\n",
              " 'going',\n",
              " 'american',\n",
              " 'home',\n",
              " 'best']"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FERAJrYdWOsx",
        "outputId": "f576a962-549b-440a-f70f-08b74bd9b918"
      },
      "source": [
        "#get length of vocabulary\n",
        "\n",
        "print(vectorizer.vocabulary_size()) \n",
        "# putput is 200k, same as max_tokens set into the tokenizer"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oyBYZ6ahkx5Z"
      },
      "source": [
        "# dictionary mapping words to their indices:\n",
        "voc = vectorizer.get_vocabulary()\n",
        "word_index = dict(zip(voc, range(len(voc))))"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eN4x4ANLctOs",
        "outputId": "4e444cd7-ff2f-4783-84e1-101e6dacc83f"
      },
      "source": [
        "#download glove embeddings\n",
        "!wget http://nlp.stanford.edu/data/glove.6B.zip\n",
        "!unzip -q glove.6B.zip"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-09-25 10:17:36--  http://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
            "--2021-09-25 10:17:36--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
            "--2021-09-25 10:17:37--  http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip’\n",
            "\n",
            "glove.6B.zip        100%[===================>] 822.24M  5.17MB/s    in 2m 40s  \n",
            "\n",
            "2021-09-25 10:20:17 (5.14 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "3G_IDhVHj_NG",
        "outputId": "a641ee0d-bf6c-4c65-d098-35460408e756"
      },
      "source": [
        "pwd"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content'"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6bheCmV_kBFH",
        "outputId": "487b3b65-06ca-4cd2-e8de-858c5c32a46d"
      },
      "source": [
        "ls"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0m\u001b[01;34mdrive\u001b[0m/             glove.6B.200d.txt  glove.6B.50d.txt  \u001b[01;34msample_data\u001b[0m/\n",
            "glove.6B.100d.txt  glove.6B.300d.txt  glove.6B.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6WERzXM1dbsa",
        "outputId": "a368501a-867f-4eaf-b49f-8165a3d22186"
      },
      "source": [
        "import os\n",
        "\n",
        "#Create a dictionary mapping words (strings) to their NumPy vector representation:\n",
        "path_to_glove_file = os.path.join(\n",
        "    os.path.expanduser(\"~\"), \"/content/glove.6B.100d.txt\"\n",
        ")\n",
        "\n",
        "embeddings_index = {}\n",
        "with open(path_to_glove_file) as f:\n",
        "    for line in f:\n",
        "        word, coefs = line.split(maxsplit=1)\n",
        "        coefs = np.fromstring(coefs, \"f\", sep=\" \")\n",
        "        embeddings_index[word] = coefs\n",
        "\n",
        "print(\"Found %s word vectors.\" % len(embeddings_index))"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 400000 word vectors.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8CxEdU7Uj36E",
        "outputId": "17f256a7-98c7-40fe-ba1b-9ce215f49866"
      },
      "source": [
        "#create embedding matrix\n",
        "\n",
        "num_tokens = len(voc) + 2\n",
        "embedding_dim = 100\n",
        "hits = 0\n",
        "misses = 0\n",
        "\n",
        "# Prepare embedding matrix\n",
        "embedding_matrix = np.zeros((num_tokens, embedding_dim))\n",
        "for word, i in word_index.items():\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        # Words not found in embedding index will be all-zeros.\n",
        "        # This includes the representation for \"padding\" and \"OOV\"\n",
        "        embedding_matrix[i] = embedding_vector\n",
        "        hits += 1\n",
        "    else:\n",
        "        misses += 1\n",
        "print(\"Converted %d words (%d misses)\" % (hits, misses))"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Converted 18084 words (1916 misses)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rdUFZP8GlDIV"
      },
      "source": [
        "#create Embedding layer\n",
        "from tensorflow.keras.layers import Embedding\n",
        "\n",
        "embedding_layer = Embedding(\n",
        "    num_tokens,\n",
        "    embedding_dim,\n",
        "    embeddings_initializer=keras.initializers.Constant(embedding_matrix),\n",
        "    trainable=False,\n",
        ")"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QI3JJ-y6lQSQ"
      },
      "source": [
        "#Building the LSTM Model\n",
        "model_lstm = tf.keras.Sequential([\n",
        "    embedding_layer,\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(16)),\n",
        "    tf.keras.layers.Dense(6, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zoz7NyPIlftf",
        "outputId": "e4d97ae1-7ea3-466d-fc41-5b6a9defe72e"
      },
      "source": [
        "model_lstm.summary()"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, None, 100)         2000200   \n",
            "_________________________________________________________________\n",
            "bidirectional (Bidirectional (None, 32)                14976     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 6)                 198       \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 7         \n",
            "=================================================================\n",
            "Total params: 2,015,381\n",
            "Trainable params: 15,181\n",
            "Non-trainable params: 2,000,200\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TAv-Ca1dmsUI"
      },
      "source": [
        "x_train = vectorizer(np.array([[s] for s in train_samples])).numpy()\n",
        "x_val = vectorizer(np.array([[s] for s in val_samples])).numpy()\n",
        "\n",
        "y_train = np.array(train_labels)\n",
        "y_val = np.array(val_labels)"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9KEFLJOsmxPq",
        "outputId": "e0ec149e-67ae-4ff3-c003-c06c44fcb823"
      },
      "source": [
        "model_lstm.compile(\n",
        "    loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"]\n",
        ")\n",
        "model_lstm.fit(x_train, y_train, batch_size=128, epochs=20, validation_data=(x_val, y_val))"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "179/179 [==============================] - 23s 81ms/step - loss: 0.6046 - accuracy: 0.6789 - val_loss: 0.5430 - val_accuracy: 0.7260\n",
            "Epoch 2/20\n",
            "179/179 [==============================] - 14s 76ms/step - loss: 0.5073 - accuracy: 0.7538 - val_loss: 0.5116 - val_accuracy: 0.7451\n",
            "Epoch 3/20\n",
            "179/179 [==============================] - 14s 76ms/step - loss: 0.4728 - accuracy: 0.7762 - val_loss: 0.4874 - val_accuracy: 0.7608\n",
            "Epoch 4/20\n",
            "179/179 [==============================] - 14s 76ms/step - loss: 0.4456 - accuracy: 0.7915 - val_loss: 0.4779 - val_accuracy: 0.7645\n",
            "Epoch 5/20\n",
            "179/179 [==============================] - 14s 76ms/step - loss: 0.4253 - accuracy: 0.8041 - val_loss: 0.4728 - val_accuracy: 0.7702\n",
            "Epoch 6/20\n",
            "179/179 [==============================] - 14s 76ms/step - loss: 0.4067 - accuracy: 0.8144 - val_loss: 0.4595 - val_accuracy: 0.7765\n",
            "Epoch 7/20\n",
            "179/179 [==============================] - 14s 76ms/step - loss: 0.3920 - accuracy: 0.8218 - val_loss: 0.4555 - val_accuracy: 0.7819\n",
            "Epoch 8/20\n",
            "179/179 [==============================] - 14s 76ms/step - loss: 0.3784 - accuracy: 0.8305 - val_loss: 0.4613 - val_accuracy: 0.7784\n",
            "Epoch 9/20\n",
            "179/179 [==============================] - 14s 76ms/step - loss: 0.3665 - accuracy: 0.8360 - val_loss: 0.4647 - val_accuracy: 0.7835\n",
            "Epoch 10/20\n",
            "179/179 [==============================] - 14s 76ms/step - loss: 0.3548 - accuracy: 0.8443 - val_loss: 0.4508 - val_accuracy: 0.7870\n",
            "Epoch 11/20\n",
            "179/179 [==============================] - 14s 76ms/step - loss: 0.3456 - accuracy: 0.8475 - val_loss: 0.4706 - val_accuracy: 0.7837\n",
            "Epoch 12/20\n",
            "179/179 [==============================] - 14s 76ms/step - loss: 0.3367 - accuracy: 0.8523 - val_loss: 0.4516 - val_accuracy: 0.7901\n",
            "Epoch 13/20\n",
            "179/179 [==============================] - 14s 76ms/step - loss: 0.3276 - accuracy: 0.8557 - val_loss: 0.4542 - val_accuracy: 0.7900\n",
            "Epoch 14/20\n",
            "179/179 [==============================] - 14s 76ms/step - loss: 0.3218 - accuracy: 0.8608 - val_loss: 0.4539 - val_accuracy: 0.7914\n",
            "Epoch 15/20\n",
            "179/179 [==============================] - 14s 76ms/step - loss: 0.3124 - accuracy: 0.8660 - val_loss: 0.4595 - val_accuracy: 0.7875\n",
            "Epoch 16/20\n",
            "179/179 [==============================] - 14s 76ms/step - loss: 0.3058 - accuracy: 0.8670 - val_loss: 0.4619 - val_accuracy: 0.7903\n",
            "Epoch 17/20\n",
            "179/179 [==============================] - 14s 76ms/step - loss: 0.3008 - accuracy: 0.8707 - val_loss: 0.4612 - val_accuracy: 0.7882\n",
            "Epoch 18/20\n",
            "179/179 [==============================] - 14s 76ms/step - loss: 0.2945 - accuracy: 0.8725 - val_loss: 0.4650 - val_accuracy: 0.7872\n",
            "Epoch 19/20\n",
            "179/179 [==============================] - 13s 75ms/step - loss: 0.2884 - accuracy: 0.8754 - val_loss: 0.4800 - val_accuracy: 0.7858\n",
            "Epoch 20/20\n",
            "179/179 [==============================] - 14s 76ms/step - loss: 0.2822 - accuracy: 0.8788 - val_loss: 0.4786 - val_accuracy: 0.7858\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fafd00a4550>"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kqp-xEtrm8ua"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}